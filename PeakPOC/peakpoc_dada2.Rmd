---
title: "PeakPOC_dada2"
output: html_document
---

DADA2 processing of data for PeakPOC eukaryotic datasets.

This R-markdown document includes a pipeline for data processing of amplicon data from the PeakPOC datasets

### Version of all the programs and tools used n this R markdown. 

**R** = 3.6.1
**R studio** = 1.2.1335
**dada2** = 1.12.1

### Copying fastq files from AWI server.

```{engine='bash'}

scp mniwano@aphros.awi.de:Path/to/the/file.txt /path/to/your/local/directory

```

A total of 50 fastq files are downloaded from the server onto the local computer. 

### Loading the neccesary packages

```{r}
library("knitr")
library("dada2")
```

### Specifying the path

```{r}
path <- "C:\\Users\\MSI\\AppData\\Local\\Packages\\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\\LocalState\\rootfs\\home\\matomo\\jacobs\\BCCB_Thesis\\PeakPOC\\peakpoc_fastq\\Original"

list.files(path)
```

The directory for 50 fastq files is specified. 

### specifying the forward and reverse fastq files
String manipulation to get matched lists of the forward and reverse fastq files
```{r}
# The format of forward and reverse fastq file name is SAMPLE_NAME_R1_001.fastq and Sample_NAME_R2_00.fastq
fnFs <- sort(list.files(path, pattern = "_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "_R2_001.fastq", full.names = TRUE))

# Extract sample names, assuming files have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_L"), `[`, 1)
```

### Visualizing the quality of the fastq files before filtering and trimming

```{r}
plotQualityProfile(fnFs[1:2])
plotQualityProfile(fnRs[1:2])
```

As shown in the plot graph above, the quality of reads significantly declines at the position of 200 for the forward files and this would be the cutoff point for the truncation. Any point after 200 shows a significant decline in quality score which is not suitable for further processing.   

For reverse file, truncate position is determined at 150.
**fnFs[1:2]** = selecting first two files from the targeted fastq files in the directory

### -Assigning a variable for fastq file names after filtering and trimming.- 

```{r}
# Place filtered files in filtered subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "L001_F_filt.fastq.gz"))
names(filtFs) <- sample.names

# Reverse files
filtRs <- file.path(path, "filtered", paste0(sample.names, "L001_R_filt.fastq.gz"))
names(filtRs) <- sample.names
```

### - filtering and trimming- 
discard low quality reads and primers. 

```{r}
out <- filterAndTrim(
  fwd = fnFs,
  filt = filtFs, 
  rev = fnRs,
  filt.rev = filtRs,
  truncLen=c(200,150),
  trimLeft = c(17, 18),
  maxN=0,
  maxEE=c(1),
  truncQ=2,
  rm.phix=TRUE,
  compress=TRUE,
  multithread=TRUE)
head(out)
```

- **fwd** = The path to the input fastq files. In this case, 'fnFs'.
- **filt** = The path to the output filtered files from fwd. In this case 'filtFs'.
- **trunclen** = Legth of reads after truncation of bases. As shown above, the value for trunclen is decided at 250. 
- **maxN** = After truncation, sequences with more than maxN Ns will be discarded. Since DADA2 requires no Ns, we will stick with default value 0.
- **trimLeft** = The number of nucleotides to remove from the start of each read. If both truncLen and trimLeft are provided, filtered reads will have length truncLen-trimLeft. THis parameter is used when the fastq files still contain primer
- **maxEE** = After truncation, reads with higher than maxEE "expected errors" will be discarded. The maxEE parameter sets the maximum number of "expected errors" allowed in a read. In other words, we want to throw the read away if the read has is likely to have more than value 'maxEE' erroneous base calls. The EE is defined to be the mean of errors that would be observed in a very large collection of sequences where error rate in each read position is occured independently. Expected error is the sum of error probabilities. For instance, 
EE = sum(Probability of an error; the base is incorrect if P is the error probability) = sum(10^(-Q/10)). 
If P = 0.5 that means there is a 50% of chance that the base is wrong. Therefore, large EE number implies that the sum of probabilities of error is large as well, so if maxEE is set to low, then only the reads with small sum of error probabilities can pass through the filter (high quality reads). This time maxEE is set to 1 for the sake of high quality reads filteration and efficiency of computation to process such a large datasets. If filtered reads are too few, then please increase the maxEE value (relaxation of filter). 
- **truncQ** = Truncate reads at the first instance of a quality score less than or equal to truncQ. Default is 2 meaning that reads with quality score of 2 (p error = 0.63096) are automatically truncated since there is a 63% chance of the base being wrong. 
- **rm.phix** = If TRUE, discard reads that match against the phiX genome. Phix bacteriophage genome is typically added to illumina sequencing runs for quality monitoring. 
- **compress** = If TRUE, the output fastq files are gzipped
- **multithread** = if TRUE, input files are filtered in parallel via mclapply. It allows it paralell computation which results in faster processing time. 

### Quaity check after filtering and trimming

```{r}
plotQualityProfile(filtFs[1:2])
plotQualityProfile(filtRs[1:2])
```


The quality seems to be good! 

### -learn the error rates -
Every amplicon dataset has a different set of error rates. 
Blackline shows the estimated error rates after convergence of the machine-learning algorithm.
Redline shows the error rates expected under the nominal definition of the Q-score.
Black lines are a good fit fot the observed rates and the errror rates drop with increased quality as expected.

```{r}  
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)
plotErrors(errF, nominalQ=TRUE) 
```
- **multithread** = If TRUE, multithreading is enabled and the number of availble thread is automatically determined. Just like above, this parameter is set to TRUE for faster computation. 
- **nominalQ** =  If TRUE, plot the expected error rates (red line shown in the graph) if quality scores exactly matched their nominal definition: Q = -10 log10(p_err).

The red line is expected line based on the given quality score, the black line indicates the estimated line, and the black dots shows the observed error frequency in each consensus quality score. Ideally, the black dots should follow the track of the black line. 
From the graph above, the black dots follow the trend of black line, and the error rates drop with increased quality as expected. This is reasonable error inference. 


### Sample Inference
This process contains removal of unique sequences that were produced by error. 

```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE, pool="pseudo")
dadaRs <- dada(filtRs. err=errR, multithread=TRUE, pool="pseudo")
dadaFs[[1]]
```
- **err** = 16xN numeric matrix, or an object coercible by getErrors such as the output of the learnErrors function operated in the previous step. 'errF' is the name of variable that was used to store the result from the previous step.
- **pool** = If pool = TRUE, the algorithm will pool together all samples prior to sample inference. If pool = FALSE, sample inference is performed on each sample individually. If pool = "pseudo", the algorithm will perform pseudo-pooling between individually processed samples. In other words, when sample A has 1000 copies of of sequence Z while sample B only contains one single copy of sequence Z, sequence Z is likely to be filtered out of sample B although it was a true "singleton" among other sequences in the sample B. This is what is expected to happen when the parameter 'pool' is set to FALSE. On the other hand, when the paramter 'pool' is set to TRUE, it is going to require inconvinient over-workload of computation if the large datasets are processed. For this reason, the parameter "pseudo" option lies somewhere between these two pooling options. Pesudo option contains a two step process i which independent processing is performed twice: First on the raw data alone, and then on the raw data again but informed by priors generated from the first round of processing in the second time. Pseudo-pooling provides a more accurate resolution of ASVs. For this reason, pseudo option is used in this datasets. 

```{r}

```

